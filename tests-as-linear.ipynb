{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common statistical tests are linear models (or: how to teach stats)\n",
    "\n",
    "By Jonas Kristoffer LindelÃ¸v ([blog](https://lindeloev.net), [profile](http://personprofil.aau.dk/117060)).\n",
    "Python port by George Ho ([blog](https://eigenfoo.xyz))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: June 23, 2019\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"Last updated: {}\".format(datetime.datetime.now().strftime(\"%B %d, %Y\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The simplicity underlying common tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the common statistical models (t-test, correlation, ANOVA; chi-square, etc.) are special cases of linear models or a very close approximation. This beautiful simplicity means that there is less to learn. In particular, it all comes down to $y = a \\cdot x + b$ which most students know from highschool. Unfortunately, stats intro courses are usually taught as if each test is an independent tool, needlessly making life more complicated for students and teachers alike. \n",
    "\n",
    "This needless complexity multiplies when students try to rote learn the parametric assumptions underlying each test separately rather than deducing them from the linear model.\n",
    "\n",
    "For this reason, I think that teaching linear models first and foremost and *then* name-dropping the special cases along the way makes for an excellent teaching strategy, emphasizing *understanding* over rote learning. Since linear models are the same across frequentist, Bayesian, and permutation-based inferences, I'd argue that it's better to start with modeling than p-values, type-1 errors, Bayes factors, or other inferences.\n",
    "\n",
    "Concerning the teaching of *\"non-parametric\"* tests in intro-courses, I think that we can justify [lying-to-children](https://en.wikipedia.org/wiki/Lie-to-children) and teach \"non-parametric\"\" tests as if they are merely ranked versions of the corresponding parametric tests. It is much better for students to think \"ranks!\" than to believe that you can magically throw away assumptions. Indeed, the Bayesian equivalents of \"non-parametric\"\" tests implemented in [JASP](https://jasp-stats.org) [literally just do (latent) ranking](https://arxiv.org/abs/1712.06941) and that's it. For the frequentist \"non-parametric\"\" tests considered here, this approach is highly accurate for N > 15.\n",
    "\n",
    "Use the menu to jump to your favourite section. There are links to lots of similar (though more scattered) stuff under [sources](#links) and [teaching materials](#course). I hope that you will join in suggesting improvements or submitting improvements yourself in [the Github repo to this page](https://github.com/lindeloev/tests-as-linear). Let's make it awesome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings and toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    code_show=true; \n",
       "    function code_toggle() {\n",
       "        if (code_show){\n",
       "            $('div.cell.code_cell.rendered.selected div.input').hide();\n",
       "        } else {\n",
       "            $('div.cell.code_cell.rendered.selected div.input').show();\n",
       "        }\n",
       "        code_show = !code_show\n",
       "    } \n",
       "    $( document ).ready(code_toggle);\n",
       "    </script>\n",
       "    <a href=\"javascript:code_toggle()\">Show/hide source</a>.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def toggle_cell():\n",
    "    # From https://stackoverflow.com/q/31517194\n",
    "    tag = HTML(\"\"\"\n",
    "    <script>\n",
    "    code_show=true; \n",
    "    function code_toggle() {\n",
    "        if (code_show){\n",
    "            $('div.cell.code_cell.rendered.selected div.input').hide();\n",
    "        } else {\n",
    "            $('div.cell.code_cell.rendered.selected div.input').show();\n",
    "        }\n",
    "        code_show = !code_show\n",
    "    } \n",
    "    $( document ).ready(code_toggle);\n",
    "    </script>\n",
    "    <a href=\"javascript:code_toggle()\">Show/hide source</a>.\n",
    "    \"\"\")\n",
    "    display(tag)\n",
    "    \n",
    "toggle_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson and Spearman correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: As linear models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: the recipe for $y$ is a slope ($\\beta_1$) times $x$ plus an intercept ($\\beta_0$, aka a straight line).\n",
    "\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 x \\qquad \\mathcal{H}_0: \\beta_1 = 0$\n",
    "\n",
    "... which is a math-y way of writing the good old $y = ax + b$ (here ordered as $y = b + ax$). In R we are lazy and write `y ~ 1 + x` which R reads like `y = 1*number + x*othernumber` and the task of t-tests, lm, etc., is simply to find the numbers that best predict $y$.\n",
    "\n",
    "Either way you write it, it's an intercept ($\\beta_0$) and a slope ($\\beta_1$) yielding a straight line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Make plot here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is often simply called a **regression** model which can be extended to **multiple regression** where there are several $\\beta$s and on the right-hand side multiplied with the predictors. Everything below, from [one-sample t-test](#t1) to [two-way ANOVA](#anova2) are just special cases of this system. Nothing more, nothing less.\n",
    "\n",
    "As the name implies, the **Spearman rank correlation** is a **Pearson correlation** on rank-transformed $x$ and $y$:\n",
    "\n",
    "$rank(y) = \\beta_0 + \\beta_1 \\cdot rank(x) \\qquad \\mathcal{H}_0: \\beta_1 = 0$\n",
    "\n",
    "I'll introduce [ranks](#rank) in a minute. For now, notice that the correlation coefficient of the linear model is identical to a \"real\" Pearson correlation, but p-values are an approximation which is is [appropriate for samples greater than N=10 and almost perfect when N > 20](simulations/simulate_spearman.html).\n",
    "\n",
    "Such a nice and non-mysterious equivalence that many students are left unaware of! Visualizing them side by side including data labels, we see this rank-transformation in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Make plot here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: rank-transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rank` simply takes a list of numbers and \"replace\" them with the integers of their rank (1st smallest, 2nd smallest, 3rd smallest, etc.). So the result of the rank-transformation `rank(c(3.6, 3.4, -5.0, 8.2))` is `3, 2, 1, 4`. See that in the figure above? \n",
    "\n",
    "A *signed* rank is the same, just where we rank according to absolute size first and then add in the sign second. So the signed rank here would be `2, 1, -3, 4`. Or in code:\n",
    "\n",
    "```{r}\n",
    "signed_rank = function(x) sign(x) * rank(abs(x))\n",
    "```\n",
    "\n",
    "I hope I don't offend anyone when I say that ranks are easy; yet it's all you need to do to convert most parametric tests into their \"non-parametric\" counterparts! One interesting implication is that *many \"non-parametric tests\" are about as parametric as their parametric counterparts with means, standard deviations, homogeneity of variance, etc. - just on rank-transformed data*. That's why I put \"non-parametric\" in quotation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
